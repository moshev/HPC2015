# FMI HPC 15

![FMI HPC 15 Logo](./images/hpc_fmi_logo.jpg)

---

* За нас

* За курса

* За оценяването

---

# За Нас

---

## Димитър Трендафилов

Masthead MMORPG Game Engine Dev

Coherent Labs - Co-Founder

Advanced C++

@dimitarcl

trendafilov.dn@gmail.com

---

* СУ/ФМИ/2009

* Masthead Studios 2009-2012

* Coherent Labs since 2012

---

## Благовест Тасков

http://code-bg.com

http://github.com/savage309

@savage309

taskov@gmail.com

---

* СУ/ФМИ/2011

* Masthead 2009-2011

 * MMORPG UI with Scaleform

 * Mobile Games using C++


* Chaos Group 2011-continues

 * **V-Ray RT GPU (CUDA & OpenCL)**

* Other

 * F.U.T.

---

## Guests

* Мартин Енев (Google)

* Стоян Николов (Coherent Labs)

* Мартин Кръстев (Chaos Group)

* Други (nVidia, VMWare, ...)

---

# За Курса

---

# Изисквания

* Английски език

* С, С++ (УП, ООП, СДП, advanced)

* Операционни системи

* Компютърни архитектури

---

## Защо да не записвате този курс

 * Дава малко кредити

 * Труден е

 * С други технологии (JS) се печели повече

 * Никой софтуер/курс версия 1.0 не е небъгав. Ще бъдете използвани за бета тест.

 * Ако бъдете хванат да преписвате ще пропуснете ПОНЕ една година акамичен живот
   * Важи както за изпити/контролни, така и за проекти/домашни

---

## Ако бъдете хванат да преписвате ще пропуснете ПОНЕ една година академичен живот

Няма да бъде направен **нито един компромис**

---

## Защо да запишете този курс

* Темите които ще разгледаме се разглеждат и в други (не лоши) курсове във ФМИ.
  Практиката на други университети показва обаче, че е полезно тези теми да
  бъдат разгледани и във взаимносвързан контекст

* Фундаментален за приложения като игри и симулации

---

>"Programs must be written for people to read, and only incidentally for machines to execute" Harold Abelson

* Ние обаче ще се фокусираме върху код, на който му се случва често да се изпълнява (и пише) от машини.

* Ще си говорим за хардуер (може би повече, от колкото трябва), но в контекста на програмите, които той изпълнява.

* Ще пишем код, ще ползваме инструменти за профилиране и дебъгване.

---

### Организационни

twitter: **@HPC_FMI**

mail: **hpc.fmi@gmail.com**

github: **https://github.com/savage309/HPC2015**

---

#### References

* HPI (course **"Parallel Programing Concepts"**, Peter Troger)
* Stanford (course "Programming Massively Parallel Processors")
* lighterra.com (website)
* Andrew S. Tanenbaum books (all of them)
* C++ Concurency in action (book)
* The Art of Concurency (book)

---

#### References

* High Performance Computing (Charles Sevarance, Kevin Dowd) (book)
* Programming massively parallel processors (book)
* OpenCL Programming Guide (book)
* Compilers: Principles, Techniques, and Tools (book)
* What every programmer should know about memory (paper)
* Wikipedia (yes, Wikipedia)

---

### Оценяване

* Изпит **50%**
     * В случай, че сте свикнали на обратното - оценяването няма да е на база
       брой изписани страници
     * Освен код, може да се наложи да бъдат писани дефиниции и теореми

* Проект **30%**

* Домашни **20%**

* +Бонуси

---

 * Лекциите ще бъдат качвани online

 * Ще опитаме да имаме и видео записи в youtube, но е силно вероятно да не
   успеем за първата година на курса.

---

* Няма упражнения и ще се води в **традиционна форма** (т.е. идва някой, чете
  текст от слайдове и си тръгва).

* Курс в **дискусионна форма** (т.е. идва някой, говори си с вас, докато на
  заден фон вървят слайдове) изглежда по-добра идея, но не знаем
  точно как се прави (понеже сме имали само курсове от традиционният тип) и не
  мислим, че можем да се справим добре с него.

* Но **въпроси по всяко време** са добре дошли (и понеже въглехидратите са
  вредни (ketosis ftw), вместо тях ще получите **бонус точки**, ако преценим че
  въпросът е бил добър)

---

## What is HPC

 * HPC = High Performance Computing

 >High Performance Computing most generally refers to the practice of
 >aggregating computing power in a way that delivers much higher performance
 >than one could get out of a typical desktop computer or workstation in order
 >to solve large problems in science, engineering, or business

---

HPC курс следва да се състои от две фундаментални части:

* Програмиране на системи със споделена памет

* Програмиране на системи без споделена памет

Ние ще разгледаме **само** програмирането на системи **със** споделена памет.

---

По принцип "HPC" се ползва като термин, когато се говори за **програмиране на
суперкомпютри**.

В "медиите" обаче се ползва и като буквалното му значение, а именно "изчисления
за висока производителност", или иначе казано **"да направим нещо да работи
бързо"**. Заглавието на този курс също е с "медийното" значение.

Няма да програмираме суперкомпютри.

---

## What is HPC FMI 15

  * Big O(n) notation

    * Окей за математика, не толкова окей за програмиране

  * Not-Big-O-Based-Optimizations

  * С други думи - ще забързваме програми без да променяме техните алгоритми

---

# Въпроси ?

---

![Diode, P/N junction](./images/diode.png)
--
![Transistor, P/N junction](./images/transistor.png)

---

Logical AND

![Logical AND, P/N junction](./images/logical_and.gif)

---

## Закон на Мур

> Броят на транзисторите в един чип се удвоява приблизително всеки 12/18/24 месеца

Валиден ли е все още ?

---

![Moores Law](./images/moore.png)

---

Да, но ...

---

Нещо се случва през 2005

![Free Lunch Is Over](./images/free_lunch_is_over.png)

---


Защо компютрите вече не стават по-бързи ?

* Не стават ли ?

* До преди 2005 - на всеки Х месеца броят на транзисторите се удвоява по закона
  на Мур

* Това се случва посредством намаляне на размера на транзистора на чипа двойно

* Когато чипът е два пъти по-малък можем да вдигнем честотата два пъти

---

* size **L1 = L/2**

* voltage **V1 = V/2**

* frequency **F1 = 2F**

* density **D1 = 4D**

* power = **L \* V \* V \* F **
 * **P1 = 1/2 \* (1/2 \* 1/2 \* 2 \*2 \* 2)**
 * => **P1 = P**

 Обаче ...

---

Поради физични явления, вече не можем да намаляме **V**. Тоест ..


* size **L1 = L/2**

* voltage  <span style="color:red;">**V1 = V/2**</span>

* frequency **F1 = 2F**

* density **D1 = 4D**

* power = **L \* V \* V \* F **
 * **P1 = 1/2 \* 2 \*2 \* 2**
 * => <span style="color:red;">**P1 = 4P**</span>


---

**Static Power** - leakage of transistors while being inactive

**Dynamic Power** - energy needed to switch gate

---

 ![Leakage](./images/leakage.png)

---

Ват на кв. см. в микропроцесорите

 ![Power per cm^2](./images/power_per_cm2.png)

---

![Taylor, 2OO9](./images/Taylor_2OO9.png)

---

# Как работи процесора ?

---

1. Fetch
2. Decode
3. Execute
4. Write-back

<img src="./images/pipeline1.svg" alt="lighterra.com" style="width: 685px;"/>

---

Има **3 начина** да получим по-голяма производителност - и това не се отнася
само до програмирането, ами изобщо

1. Работи по-усърдно / Work Harder

2. Работи по-умно / Work Smarter

3. Повикай помощ / Get Help

---

В контекста на процесорите:

1. Увеличена честота

2. Кешове / branch prediction / out of order / etc

3. Multicore / ILP / Auto SIMD

---


1. Валът на мощността

2. Валът на паметта

3. Валът на имплицитният паралелизъм 

<img src="./images/wall.png" alt="the wall" style="width: 685px;"/>

---

Pipeline

Do the CPU phases in parallel - write back result, as executing something else,
as decoding 3rd, as fetching 4th ..

<img src="./images/pipeline2.svg" alt="lighterra.com" style="width: 685px;"/>

Problem : dependencies ...

---

Resolving dependencies

```
       for (int i = 0; i < numItems; ++i) {
            x = y[i] * z;    /// <----
            q += z + x + x;
            x = a + b;       /// <----
        }

        //////////////

        for (int i =0 ; i < numItems; ++i) {
            float x0 = y[i] * z;
            q += z + x0 + x0;
            x = a + b;
        }
```

---

Resolving dependencies in **reduction**
```
for (int i = 0; i < size; ++i)
    m = max(arr[i], m);
```
Lets unroll ..
```
for (int i = 0; i < size / 4; i+=4) {
    m = max(arr[i], m);
    m = max(arr[i+1], m); /// <----
    m = max(arr[i+2], m); /// <----
    m = max(arr[i+3], m); /// <----
}
```
Fixed:
```
m0=m1=m2=m3=-inf;
for (int i = 0; i < size/4; i+=4) {
    m0 = max(m0, arr[i+0]);
    m1 = max(m1, arr[i+1]);
    m2 = max(m2, arr[i+2]);
    m3 = max(m3, arr[i+3]);
}
m = max(m0, m1, m2, m3);
```


---

бел.ред:
plans for the next slides - introduction to
Instruction Level Parallelism
ILP wall
Memory Caches
Memory wall
SIMD
следващите слайдове за сега са разбъркани и следва да бъдат подредени ...

---


| Old        | New           |
| ------------- |:-------------:|
| Power is free, transistors are expensive      | Power Wall |
| Only dynamic power counts    | Static leakage is 40%      |
| Multiply is slow, load-and-store is fast | Memory wall      |
| ILP get better all the time, load-and-store is fast | ILP wall |
| Parallelization is not worth it | 75% per year before, 15% per year now    |
| Processor frequency goes up every X months | Number of cores goe up every X months      |

---

* Single core performance per year ~(2 to 15)% per year

* Multicore performance increase ~75% per year

---

FMAD double = 50pj

Moving 64b 1mm = 25pj

___

<img style="float: right;" src="./images/gpu.png" width="400px">

64b 10mm = 250pj

64b "off chip" = 1000pj

64b DRAM = 10000pj

12 TFLOPS ?= 300W
___

*"ALUs are like kids these days - easy to acquire, hard to feed" (B. Dally)*

---

“The Free Lunch Is Over: A Fundamental Turn Toward Concurrency in Software”
(2005, Sutter)

“30x CPU performance increases in the next 50 years” (2500x for the last 30
years)

“100 GHz CPU == Чип с размер 2 милиметра”

**Производителност = Паралелизъм**

**Ефикасност = Локалност**

Еднонишково оптимизираните процесори (и езици!) са отрицание на това ("светът е
плосък")

---

## Производителност = Паралелизъм

___

## Ефикасност = Локалност

---

>“Software does not run in a magic fairy ether powered by the fevered dreams of
>CS PhDs” Branimir Karadzic

